{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Measure for FASHION MNIST via CNN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: crossentropy, throttle\n",
    "using Flux: @epochs\n",
    "using MLDatasets\n",
    "using Base.Iterators: partition\n",
    "using Flux: onehotbatch\n",
    "using Random\n",
    "train_x, train_y = FashionMNIST.traindata();\n",
    "test_x,  test_y  = FashionMNIST.testdata();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model for CNN with filter size (3,3), max pooling size (2,2) and using relu activation functions for intermediate \n",
    "layers, softmax for the outer layer. For the preprocessing convolutional layers we use output dimensions in successions; 32,64,128. \n",
    "\n",
    "We further improve the accuracy to 86.75% amd with more hyper parameter tuning, it is quite likely that accuracy could go higher than 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1, 10000)\n",
      "(10, 10000)\n",
      "Array{Float64,4}\n",
      "Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 2\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 3\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 4\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 5\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 6\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 7\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 8\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 9\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 10\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 11\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 12\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 13\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 14\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 15\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 16\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 17\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 18\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 19\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 20\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 21\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 22\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 23\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 24\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 25\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 26\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 27\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 28\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 29\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 30\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 31\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 32\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 33\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 34\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 35\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 36\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 37\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 38\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 39\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 40\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 41\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 42\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 43\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 44\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 45\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 46\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 47\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 48\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 49\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n",
      "┌ Info: Epoch 50\n",
      "└ @ Main /home/ashvin/.julia/packages/Flux/rcN9D/src/optimise/train.jl:93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11895.757063 seconds (21.54 G allocations: 6.462 TiB, 39.07% gc time)\n",
      "86.75\n"
     ]
    }
   ],
   "source": [
    "using Flux: onecold\n",
    "using Statistics\n",
    "function CNN(train_x, train_y, test_input, test_output, iter = 10, call = 1, train_examples = 2000, batch_size = 50)\n",
    "\n",
    "    model = Chain(\n",
    "        Conv((3,3), 1=>32, relu),\n",
    "        x -> maxpool(x, (2,2)),\n",
    "        #x -> (Dropout(0.25))(x),\n",
    "        Conv((3,3), 32=>64, relu),\n",
    "        x -> maxpool(x, (2,2)),\n",
    "        Conv((3,3), 64=>128, relu),\n",
    "        x -> maxpool(x, (2,2)),\n",
    "        x -> reshape(x, :, size(x, 4)),\n",
    "        Dense(128, 10),\n",
    "        softmax)\n",
    "\n",
    "    loss(x, y) = crossentropy(model(x), y)\n",
    "    opt = ADAM(params(model))\n",
    "    trainIndex = randperm(size(train_x)[end])[1:2000]\n",
    "    trainData = []\n",
    "    for batch in partition(1:train_examples, batch_size)\n",
    "        trainXFloat = Float64.(train_x[:, :, batch])\n",
    "        trainXReshaped = reshape(trainXFloat, (28, 28, 1, length(batch)))\n",
    "        trainY = onehotbatch(train_y[batch], 0:9)\n",
    "        push!(trainData, (trainXReshaped, trainY))\n",
    "    end\n",
    "test_foracc_input = deepcopy(test_input)\n",
    "test_foracc_output = deepcopy(test_output)\n",
    "test_input = reshape(test_input, (size(test_input)[1],size(test_input)[2],1,size(test_input)[3]))    \n",
    "test_output = onehotbatch(test_output, 0:9)\n",
    "test_input = convert(Array{Float64}, test_input);\n",
    "\n",
    "println(size(test_input))\n",
    "println(size(test_output))\n",
    "println(typeof(test_input))\n",
    "println(typeof(test_output))\n",
    "    if call == 0\n",
    "        callback() = @show(loss(test_input, test_output))    \n",
    "        @time @epochs iter Flux.train!(loss, trainData, opt, cb = throttle(callback, 5))\n",
    "    else\n",
    "        \n",
    "        @time @epochs iter Flux.train!(loss, trainData, opt)\n",
    "    end\n",
    "predicted = model(reshape(Float64.(test_foracc_input), (28, 28, 1, 10000)))\n",
    "accuracy = mean(onecold(predicted).-1 .== test_foracc_output)\n",
    "println(accuracy*100)   \n",
    "return accuracy    \n",
    "end\n",
    "acc = CNN(train_x,train_y, test_x, test_y, 50,1,60000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
